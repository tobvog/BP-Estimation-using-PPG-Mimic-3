{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0236d4",
   "metadata": {},
   "source": [
    "# Demonstration of ResNet with 6 Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c6ce8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12062a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from imports.DataGenerator_Outp6 import DataGenerator\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from tensorflow import  squeeze\n",
    "from tensorflow.keras.layers import Input, Conv1D, Reshape, LayerNormalization, ReLU, BatchNormalization, Add, AveragePooling1D, Flatten, Dense, GRU, concatenate, Dropout \n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6caed8",
   "metadata": {},
   "source": [
    "### Loading Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c427a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_main = \"C:/Users/vogel/Desktop/Study/Master BMIT/1.Semester/Programmierprojekt/feat_new/\"\n",
    "files = os.listdir(path_main+\"derivations/dev0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc2975",
   "metadata": {},
   "source": [
    "### Functions for building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11bcc60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet Block\n",
    "def resnet_block(inp, batch_size, num_filter, kernel_sizes=[8,5,3], pool_size=3, pool_stride_size=2):\n",
    "    def conv_block(inp, batch_size, num_filter, kernel_size):\n",
    "        outp = Conv1D(kernel_size=kernel_size, filters=num_filter, padding=\"same\")(inp)\n",
    "        outp = BatchNormalization()(outp)\n",
    "        outp = ReLU()(outp)       \n",
    "        return outp\n",
    "    \n",
    "    def create_output_long(inp, batch_size, num_filter, kernel_sizes):\n",
    "        outp = inp\n",
    "        for i in range(0, len(kernel_sizes)):\n",
    "            outp = conv_block(outp, batch_size, num_filter, kernel_sizes[i])\n",
    "        return outp\n",
    "    \n",
    "    def create_output_short(inp, num_filter):\n",
    "        outp = Conv1D(kernel_size=1, filters=num_filter, padding=\"same\")(inp)\n",
    "        outp = BatchNormalization()(outp)\n",
    "        return outp\n",
    "    \n",
    "    outp_long = create_output_long(inp, batch_size, num_filter, kernel_sizes)\n",
    "    outp_short = create_output_short(inp, num_filter)\n",
    "\n",
    "    outp = Add()([outp_long, outp_short])\n",
    "\n",
    "    if len(outp.shape) == 4:     \n",
    "        outp = squeeze(outp, axis=1)\n",
    "\n",
    "    outp = AveragePooling1D(pool_size=pool_size, strides=pool_stride_size)(outp)\n",
    "    \n",
    "    return outp\n",
    "\n",
    "# Spectral Block\n",
    "def spec_temp_block(inp, batch_size):\n",
    "\n",
    "    outp = tf.signal.stft(inp, frame_length=128, frame_step=64)\n",
    "    outp = tf.abs(outp)\n",
    "    outp = LayerNormalization()(outp)\n",
    "    outp = Reshape((8*batch_size,65))(outp)\n",
    "    outp = GRU(65)(outp)\n",
    "    outp = Flatten()(outp)\n",
    "    outp = Dense(32, activation=\"relu\", kernel_regularizer=l2(0.001))(outp)\n",
    "    outp = BatchNormalization()(outp)\n",
    "    \n",
    "    return outp\n",
    "   \n",
    "# Create blocks of the network \n",
    "def net_blocks(batch_size):\n",
    "    inp_time0 = Input(shape=(batch_size, 624), name=\"input_time0\")\n",
    "    inp_spec0 = Input(shape=(batch_size, 624), name=\"input_spec0\")\n",
    "    inp_time1 = Input(shape=(batch_size, 624), name=\"input_time1\")\n",
    "    inp_spec1 = Input(shape=(batch_size, 624), name=\"input_spec1\")\n",
    "    inp_time2 = Input(shape=(batch_size, 624), name=\"input_time2\")\n",
    "    inp_spec2 = Input(shape=(batch_size, 624), name=\"input_spec2\")\n",
    "    \n",
    "    outp_time0 = resnet_block(inp_time0, batch_size=batch_size, num_filter=64)\n",
    "    outp_spec0 = spec_temp_block(inp_spec0, batch_size=batch_size)\n",
    "    outp_time1 = resnet_block(inp_time1, batch_size=batch_size, num_filter=64)\n",
    "    outp_spec1 = spec_temp_block(inp_spec1, batch_size=batch_size)\n",
    "    outp_time2 = resnet_block(inp_time2, batch_size=batch_size, num_filter=64)\n",
    "    outp_spec2 = spec_temp_block(inp_spec2, batch_size=batch_size)\n",
    "    \n",
    "    for i in range(0,4):\n",
    "        outp_time0 = resnet_block(outp_time0, batch_size=batch_size, num_filter=128)\n",
    "        outp_time1 = resnet_block(outp_time1, batch_size=batch_size, num_filter=128)\n",
    "        outp_time2 = resnet_block(outp_time2, batch_size=batch_size, num_filter=128)\n",
    "        \n",
    "    model_time0 = keras.Model(inp_time0, outp_time0)#, name=model_names[0])\n",
    "    model_spec0 = keras.Model(inp_spec0, outp_spec0)#, name=model_names[0])\n",
    "    model_time1 = keras.Model(inp_time1, outp_time1)#, name=model_names[1])\n",
    "    model_spec1 = keras.Model(inp_spec1, outp_spec1)#, name=model_names[1])\n",
    "    model_time2 = keras.Model(inp_time2, outp_time2)#, name=model_names[2])\n",
    "    model_spec2 = keras.Model(inp_spec2, outp_spec2)#, name=model_names[2])\n",
    "        \n",
    "    return [model_time0, model_time1, model_time2], [model_spec0, model_spec1, model_spec2], [inp_time0, inp_time1, inp_time2], [inp_spec0, inp_spec1, inp_spec2]\n",
    "\n",
    "# Concatenate blocks of equal kind\n",
    "def concat_blocks(inp0, inp1, inp2, resblock): \n",
    "    outp = concatenate([inp0, inp1, inp2], axis=-1)\n",
    "    \n",
    "    if resblock==True:\n",
    "        outp = BatchNormalization()(outp)\n",
    "        outp = GRU(64)(outp)\n",
    "    outp = BatchNormalization()(outp)\n",
    "    \n",
    "    return  outp\n",
    "\n",
    "# Create Batches\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a34ee",
   "metadata": {},
   "source": [
    "### Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e4647d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datagenerator\n",
      "Creating Model\n",
      "Epoch 1/5\n",
      "455/455 [==============================] - 173s 372ms/step - loss: 4770.2646 - mae: 56.3801 - val_loss: 4798.1499 - val_mae: 66.0470\n",
      "Epoch 2/5\n",
      "455/455 [==============================] - 162s 356ms/step - loss: 0.6733 - mae: 0.1472 - val_loss: 5846.2090 - val_mae: 64.2544\n",
      "Epoch 3/5\n",
      "455/455 [==============================] - 162s 356ms/step - loss: 0.0425 - mae: 0.0045 - val_loss: 2042.6367 - val_mae: 26.8591\n",
      "Epoch 4/5\n",
      "455/455 [==============================] - 160s 352ms/step - loss: 0.0278 - mae: 6.8916e-04 - val_loss: 5036.0161 - val_mae: 68.0639\n",
      "Epoch 5/5\n",
      "455/455 [==============================] - 164s 360ms/step - loss: 0.0175 - mae: 0.0000e+00 - val_loss: 2251.5767 - val_mae: 23.4242\n",
      "Loading Datagenerator\n",
      "Creating Model\n",
      "Epoch 1/5\n",
      "852/852 [==============================] - 321s 371ms/step - loss: 4764.4087 - mae: 57.9463 - val_loss: 10847.3203 - val_mae: 95.3891\n",
      "Epoch 2/5\n",
      "852/852 [==============================] - 305s 358ms/step - loss: 0.0412 - mae: 0.0223 - val_loss: 11282.8398 - val_mae: 98.9455\n",
      "Epoch 3/5\n",
      "852/852 [==============================] - 293s 343ms/step - loss: 0.0172 - mae: 0.0000e+00 - val_loss: 11282.8262 - val_mae: 98.9455\n",
      "Epoch 4/5\n",
      "852/852 [==============================] - 290s 340ms/step - loss: 0.0059 - mae: 0.0000e+00 - val_loss: 11282.8193 - val_mae: 98.9455\n",
      "Epoch 5/5\n",
      "852/852 [==============================] - 290s 340ms/step - loss: 0.0012 - mae: 0.0000e+00 - val_loss: 11282.8174 - val_mae: 98.9455\n",
      "Loading Datagenerator\n",
      "Creating Model\n",
      "Epoch 1/5\n",
      "430/430 [==============================] - 206s 460ms/step - loss: 2730.9421 - mae: 38.4057 - val_loss: 2100.0044 - val_mae: 42.6065\n",
      "Epoch 2/5\n",
      "430/430 [==============================] - 165s 384ms/step - loss: 0.0608 - mae: 0.0303 - val_loss: 0.0867 - val_mae: 0.2051\n",
      "Epoch 3/5\n",
      "430/430 [==============================] - 165s 384ms/step - loss: 0.0373 - mae: 0.0010 - val_loss: 0.0308 - val_mae: 0.0000e+00\n",
      "Epoch 4/5\n",
      "430/430 [==============================] - 149s 346ms/step - loss: 0.0254 - mae: 3.7057e-07 - val_loss: 0.0205 - val_mae: 0.0000e+00\n",
      "Epoch 5/5\n",
      "430/430 [==============================] - 135s 315ms/step - loss: 0.0164 - mae: 1.1295e-05 - val_loss: 0.0128 - val_mae: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Initialize kfold\n",
    "n_splits = 3\n",
    "kfold = KFold(n_splits=n_splits)\n",
    "kfold.get_n_splits(files)\n",
    "\n",
    "# Initialize Hyperparameter\n",
    "kernel_init = \"he_uniform\"\n",
    "batch_size = 256\n",
    "l2_lambda = 0.001   \n",
    "\n",
    "\n",
    "all_mae_sbp, all_mae_dbp = [], []\n",
    "for nr_fold, (train_index, test_index) in enumerate(kfold.split(files)): \n",
    "    \n",
    "    # Separate training, validation and test ids\n",
    "    train_index, val_index = train_test_split(train_index, test_size=0.2)\n",
    "    train_id = [files[x] for x in train_index]\n",
    "    val_id = [files[x] for x in val_index]\n",
    "    test_id = [files[x] for x in test_index]\n",
    "    \n",
    "    # Generators\n",
    "    print(\"Loading Datagenerator\")\n",
    "    generator_train = DataGenerator(path_main, train_id, batch_size=batch_size)\n",
    "    generator_val = DataGenerator(path_main, val_id, batch_size=batch_size)\n",
    "    generator_test = DataGenerator(path_main, test_id, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Build ResNet blocks\n",
    "    print(\"Creating Model\")\n",
    "    model_time, model_spec, input_time, input_spec = net_blocks(batch_size)\n",
    "\n",
    "    \n",
    "    # Concatenate all ResNet and all Spetrogram blocks\n",
    "    concat_time = concat_blocks(input_time[0], input_time[1], input_time[2], resblock=True)\n",
    "    concat_spec = concat_blocks(input_spec[0], input_spec[1], input_spec[2], resblock=False)\n",
    "        \n",
    "\n",
    "    # Concatenate ResNet and Spectrogram and build rest of the model\n",
    "    concat_spec = Reshape((1, concat_spec.shape[1]*concat_spec.shape[2]))(concat_spec)\n",
    "    concat_spec = squeeze(concat_spec, axis=1)\n",
    "    merged = concatenate([concat_time, concat_spec])\n",
    "    merged_outp = Dense(32, activation=\"relu\", kernel_regularizer=l2(l2_lambda), kernel_initializer=kernel_init)(merged)\n",
    "    merged_outp = Dropout(0.2)(merged_outp)\n",
    "    merged_outp = Dense(32, activation=\"relu\", kernel_regularizer=l2(l2_lambda), kernel_initializer=kernel_init)(merged_outp)\n",
    "    merged_outp = Dropout(0.2)(merged_outp)\n",
    "    merged_outp = Dense(2, activation='relu')(merged_outp)\n",
    "\n",
    "    final_model = keras.Model(inputs=[input_time[0],\n",
    "                                    input_time[1],\n",
    "                                    input_time[2],\n",
    "                                    input_spec[0],   \n",
    "                                    input_spec[1],      \n",
    "                                    input_spec[2]],\n",
    "                                    outputs=merged_outp,\n",
    "                                    name='Final_Model')\n",
    "    \n",
    "    \n",
    "    optimizer = optimizers.RMSprop(learning_rate=0.0001)\n",
    "    \n",
    "    es = EarlyStopping(monitor=\"mae\", patience=5)\n",
    "    mcp = ModelCheckpoint('best_model'+str(nr_fold)+'.h5', monitor='val_loss', save_best_only=True)\n",
    "    final_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    # print(final_model.summary())\n",
    "    \n",
    "    final_model.fit(generator_train, \n",
    "                    validation_data=generator_val,\n",
    "                    epochs=5,\n",
    "                    verbose=1, \n",
    "                    callbacks=[es, mcp])\n",
    "    \n",
    "    \n",
    "    all_pred = []\n",
    "    all_true = []\n",
    "    for batch_index in range(generator_test.__len__()):\n",
    "        #print(batch_index)\n",
    "        batch_data, batch_true_labels = generator_test.__getitem__(batch_index)\n",
    "\n",
    "        batch_pred = final_model.predict(batch_data, verbose=0)\n",
    "        all_pred.append(batch_pred)\n",
    "        sbp_mean = np.mean(batch_true_labels[:,0])\n",
    "        dbp_mean = np.mean(batch_true_labels[:,1])\n",
    "        all_true.append(np.array([sbp_mean, dbp_mean]))\n",
    "\n",
    "    all_pred = np.concatenate(all_pred, axis=0)\n",
    "    all_true = np.array(all_true)\n",
    "\n",
    "    mae_sbp = mean_absolute_error(all_pred[:,0], all_true[:,0])\n",
    "    mae_dbp = mean_absolute_error(all_pred[:,1], all_true[:,1])\n",
    "\n",
    "    all_mae_sbp.append(mae_sbp)\n",
    "    all_mae_dbp.append(mae_dbp)\n",
    "    \n",
    "mae_sbp_mean = np.mean(all_mae_sbp)\n",
    "mae_dbp_mean = np.mean(all_mae_dbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c977a753",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a28dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE of SBP:  49.25312149861262\n",
      "Mean MAE of DBP:  28.410461674633126\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean MAE of SBP: \", mae_sbp_mean)\n",
    "print(\"Mean MAE of DBP: \", mae_dbp_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dcd3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
