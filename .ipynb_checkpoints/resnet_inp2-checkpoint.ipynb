{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b360f4",
   "metadata": {},
   "source": [
    "# Demonstration of ResNet with 2 Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a14bc6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "facb6155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from DataGenerator_Outp2 import DataGenerator\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from tensorflow import  squeeze\n",
    "from tensorflow.keras.layers import Input, Conv1D, Reshape, LayerNormalization, ReLU, BatchNormalization, Add, AveragePooling1D, Flatten, Dense, GRU, concatenate, Dropout \n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9491214",
   "metadata": {},
   "source": [
    "### Loading subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f8c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_main = \"C:/Users/vogel/Desktop/Study/Master BMIT/1.Semester/Programmierprojekt/feat_new/\"\n",
    "files = os.listdir(path_main+\"derivations/dev0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d8d24",
   "metadata": {},
   "source": [
    "### Functions for building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66efdde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet Block\n",
    "def resnet_block(inp, batch_size, num_filter, kernel_sizes=[8,5,3], pool_size=3, pool_stride_size=2):\n",
    "    def conv_block(inp, batch_size, num_filter, kernel_size):\n",
    "        outp = Conv1D(kernel_size=kernel_size, filters=num_filter, padding=\"same\")(inp)\n",
    "        outp = BatchNormalization()(outp)\n",
    "        outp = ReLU()(outp)       \n",
    "        return outp\n",
    "    \n",
    "    def create_output_long(inp, batch_size, num_filter, kernel_sizes):\n",
    "        outp = inp\n",
    "        for i in range(0, len(kernel_sizes)):\n",
    "            outp = conv_block(outp, batch_size, num_filter, kernel_sizes[i])\n",
    "        return outp\n",
    "    \n",
    "    def create_output_short(inp, num_filter):\n",
    "        outp = Conv1D(kernel_size=1, filters=num_filter, padding=\"same\")(inp)\n",
    "        outp = BatchNormalization()(outp)\n",
    "        return outp\n",
    "    \n",
    "    outp_long = create_output_long(inp, batch_size, num_filter, kernel_sizes)\n",
    "    outp_short = create_output_short(inp, num_filter)\n",
    "\n",
    "    outp = Add()([outp_long, outp_short])\n",
    "\n",
    "    if len(outp.shape) == 4:     \n",
    "        outp = squeeze(outp, axis=1)\n",
    "\n",
    "    outp = AveragePooling1D(pool_size=pool_size, strides=pool_stride_size)(outp)\n",
    "    \n",
    "    return outp\n",
    "\n",
    "# Spectral Block\n",
    "def spec_temp_block(inp, batch_size):\n",
    "\n",
    "    outp = tf.signal.stft(inp, frame_length=128, frame_step=64)\n",
    "    outp = tf.abs(outp)\n",
    "    outp = LayerNormalization()(outp)\n",
    "    outp = Reshape((8*batch_size,65))(outp)\n",
    "    outp = GRU(64)(outp)\n",
    "    outp = Flatten()(outp)\n",
    "    outp = Dense(32, activation=\"relu\", kernel_regularizer=l2(0.001))(outp)\n",
    "    outp = BatchNormalization()(outp)\n",
    "    \n",
    "    return outp\n",
    "   \n",
    "# Create blocks of the network \n",
    "def net_blocks(batch_size):\n",
    "    inp_time = Input(shape=(batch_size, 624), name=\"input_time0\")\n",
    "    inp_spec = Input(shape=(batch_size, 624), name=\"input_spec0\")\n",
    "\n",
    "    \n",
    "    outp_time = resnet_block(inp_time, batch_size=batch_size, num_filter=64)\n",
    "    outp_spec = spec_temp_block(inp_spec, batch_size=batch_size)\n",
    "\n",
    "    for i in range(0,4):\n",
    "        outp_time = resnet_block(outp_time, batch_size=batch_size, num_filter=128)\n",
    "\n",
    "    model_time = keras.Model(inp_time, outp_time)\n",
    "    model_spec = keras.Model(inp_spec, outp_spec)\n",
    "        \n",
    "    return model_time, model_spec, inp_time, inp_spec, outp_time, outp_spec\n",
    "\n",
    "# Create Batches\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7e5de0",
   "metadata": {},
   "source": [
    "### Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e056dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datagenerator\n",
      "Creating Model\n",
      "Counting Subjects\n",
      "Counting Subject no  1\n",
      "Counting Subject no  2\n",
      "Counting Subjects\n",
      "Counting Subject no  1\n",
      "Counting Subject no  2\n",
      "Counting Subject no  3\n",
      "Counting Subject no  4\n",
      "Counting Subject no  5\n",
      "Counting Subject no  6\n",
      "Counting Subject no  7\n",
      "Epoch 1/5\n",
      "409/409 [==============================] - 178s 413ms/step - loss: 5876.1270 - mae: 71.8378 - val_loss: 102885.3750 - val_mae: 227.6764\n",
      "Epoch 2/5\n",
      "409/409 [==============================] - 168s 410ms/step - loss: 1585.7666 - mae: 32.9604 - val_loss: 809816.0000 - val_mae: 850.0475\n",
      "Epoch 3/5\n",
      "409/409 [==============================] - 160s 392ms/step - loss: 1536.0983 - mae: 34.0244 - val_loss: 10010.7695 - val_mae: 74.9912\n",
      "Counting Subjects\n",
      "Counting Subject no  1\n",
      "Counting Subject no  2\n",
      "Counting Subject no  3\n",
      "Counting Subject no  4\n",
      "Counting Subject no  5\n",
      "Counting Subject no  6\n",
      "Counting Subject no  7\n",
      "Counting Subject no  8\n",
      "Counting Subject no  9\n",
      "Counting Subject no  10\n",
      "Loading Datagenerator\n",
      "Creating Model\n",
      "Counting Subjects\n",
      "Counting Subject no  1\n",
      "Counting Subject no  2\n",
      "Counting Subjects\n",
      "Counting Subject no  1\n",
      "Counting Subject no  2\n",
      "Counting Subject no  3\n",
      "Counting Subject no  4\n",
      "Counting Subject no  5\n",
      "Counting Subject no  6\n",
      "Counting Subject no  7\n",
      "Counting Subject no  8\n",
      "Epoch 1/5\n",
      "726/726 [==============================] - 277s 372ms/step - loss: 2758.0850 - mae: 44.6604 - val_loss: 309044.1562 - val_mae: 489.9118\n",
      "Epoch 2/5\n",
      "726/726 [==============================] - 262s 361ms/step - loss: 623.2689 - mae: 19.0564 - val_loss: 58180.6016 - val_mae: 228.8764\n",
      "Epoch 3/5\n",
      "726/726 [==============================] - 266s 366ms/step - loss: 462.7123 - mae: 9.4240 - val_loss: 422164.0938 - val_mae: 612.9381\n",
      "Epoch 4/5\n",
      "726/726 [==============================] - 263s 362ms/step - loss: 558.1586 - mae: 18.1442 - val_loss: 7436.2910 - val_mae: 78.2803\n",
      "Counting Subjects\n",
      "Counting Subject no  1\n",
      "Counting Subject no  2\n",
      "Counting Subject no  3\n",
      "Counting Subject no  4\n",
      "Counting Subject no  5\n",
      "Counting Subject no  6\n",
      "Counting Subject no  7\n",
      "Counting Subject no  8\n",
      "Counting Subject no  9\n"
     ]
    }
   ],
   "source": [
    "# Initialize kfold\n",
    "n_splits = 3\n",
    "kfold = KFold(n_splits=n_splits)\n",
    "kfold.get_n_splits(files)\n",
    "\n",
    "# Initialize Hyperparameter\n",
    "kernel_init = \"he_uniform\"\n",
    "batch_size = 256\n",
    "l2_lambda = 0.001   \n",
    "\n",
    "\n",
    "all_mae_sbp, all_mae_dbp = [], []\n",
    "for train_index, test_index in kfold.split(files): \n",
    "    \n",
    "    # Separate training, validation and test ids\n",
    "    train_index, val_index = train_test_split(train_index, test_size=0.2)\n",
    "    train_id = [files[x] for x in train_index]\n",
    "    val_id = [files[x] for x in val_index]\n",
    "    test_id = [files[x] for x in test_index]\n",
    "    \n",
    "    # Initialize Datagenerator\n",
    "    print(\"Loading Datagenerator\")\n",
    "    generator_train = DataGenerator(path_main, train_id, batch_size=batch_size)\n",
    "    generator_val = DataGenerator(path_main, val_id, batch_size=batch_size)\n",
    "    generator_test = DataGenerator(path_main, test_id, batch_size=batch_size)\n",
    "\n",
    "    # Build ResNet blocks\n",
    "    print(\"Creating Model\")\n",
    "    model_time, model_spec, input_time, input_spec, outp_time, outp_spec = net_blocks(batch_size)\n",
    "    \n",
    "    # Concatenate blocks and build rest of the model\n",
    "    outp_time = Reshape((1, outp_time.shape[1]*outp_time.shape[2]))(outp_time)\n",
    "    outp_time = squeeze(outp_time, axis=1)\n",
    "    merged = concatenate([outp_time, outp_spec])\n",
    "    merged_outp = Dense(32, activation=\"relu\", kernel_regularizer=l2(l2_lambda), kernel_initializer=kernel_init)(merged)\n",
    "    merged_outp = Dropout(0.2)(merged_outp)\n",
    "    merged_outp = Dense(32, activation=\"relu\", kernel_regularizer=l2(l2_lambda), kernel_initializer=kernel_init)(merged_outp)\n",
    "    merged_outp = Dropout(0.2)(merged_outp)\n",
    "    merged_outp = Dense(2, activation='relu')(merged_outp)\n",
    "    \n",
    "    final_model = keras.Model(inputs=[input_time,\n",
    "                            input_spec],\n",
    "                            outputs=merged_outp,\n",
    "                            name='Final_Model')\n",
    "    \n",
    "    # Initialize training\n",
    "    optimizer = optimizers.RMSprop(learning_rate=0.0001)\n",
    "    es = EarlyStopping(monitor=\"mae\", patience=1)\n",
    "    final_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    final_model.fit(generator_train, \n",
    "                    validation_data=generator_val,\n",
    "                    epochs=5,\n",
    "                    verbose=1, \n",
    "                    callbacks=[es])\n",
    "    \n",
    "    all_pred = []\n",
    "    all_true = []\n",
    "    \n",
    "    # Prediction\n",
    "    for batch_index in range(generator_test.__len__()):\n",
    "        #print(batch_index)\n",
    "        batch_data, batch_true_labels = generator_test.__getitem__(batch_index)\n",
    "\n",
    "        batch_pred = final_model.predict(batch_data, verbose=0)\n",
    "        all_pred.append(batch_pred)\n",
    "        sbp_mean = np.mean(batch_true_labels[:,0])\n",
    "        dbp_mean = np.mean(batch_true_labels[:,1])\n",
    "        all_true.append(np.array([sbp_mean, dbp_mean]))\n",
    "\n",
    "    all_pred = np.concatenate(all_pred, axis=0)\n",
    "    all_true = np.array(all_true)\n",
    "\n",
    "    mae_sbp = mean_absolute_error(all_pred[:,0], all_true[:,0])\n",
    "    mae_dbp = mean_absolute_error(all_pred[:,1], all_true[:,1])\n",
    "\n",
    "    all_mae_sbp.append(mae_sbp)\n",
    "    all_mae_dbp.append(mae_dbp)\n",
    "\n",
    "mean_mae_sbp = np.mean(all_mae_sbp)\n",
    "mean_mae_dbp = np.mean(all_mae_dbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dbafc7",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8f022c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE of SBP:  128.0551065966799\n",
      "Mean MAE of DBP:  71.31052646061138\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean MAE of SBP: \", mean_mae_sbp)\n",
    "print(\"Mean MAE of DBP: \", mean_mae_dbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0255a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
