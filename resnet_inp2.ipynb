{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b360f4",
   "metadata": {},
   "source": [
    "# Demonstration of ResNet with 2 Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a14bc6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "facb6155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from DataGenerator_Outp2 import DataGenerator\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from tensorflow import  squeeze\n",
    "from tensorflow.keras.layers import Input, Conv1D, Reshape, LayerNormalization, ReLU, BatchNormalization, Add, AveragePooling1D, Flatten, Dense, GRU, concatenate, Dropout \n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9491214",
   "metadata": {},
   "source": [
    "### Loading subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f8c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_main = \"C:/Users/vogel/Desktop/Study/Master BMIT/1.Semester/Programmierprojekt/feat_new/\"\n",
    "files = os.listdir(path_main+\"derivations/dev0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d8d24",
   "metadata": {},
   "source": [
    "### Functions for building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66efdde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet Block\n",
    "def resnet_block(inp, batch_size, num_filter, kernel_sizes=[8,5,3], pool_size=3, pool_stride_size=2):\n",
    "    def conv_block(inp, batch_size, num_filter, kernel_size):\n",
    "        outp = Conv1D(kernel_size=kernel_size, filters=num_filter, padding=\"same\")(inp)\n",
    "        outp = BatchNormalization()(outp)\n",
    "        outp = ReLU()(outp)       \n",
    "        return outp\n",
    "    \n",
    "    def create_output_long(inp, batch_size, num_filter, kernel_sizes):\n",
    "        outp = inp\n",
    "        for i in range(0, len(kernel_sizes)):\n",
    "            outp = conv_block(outp, batch_size, num_filter, kernel_sizes[i])\n",
    "        return outp\n",
    "    \n",
    "    def create_output_short(inp, num_filter):\n",
    "        outp = Conv1D(kernel_size=1, filters=num_filter, padding=\"same\")(inp)\n",
    "        outp = BatchNormalization()(outp)\n",
    "        return outp\n",
    "    \n",
    "    outp_long = create_output_long(inp, batch_size, num_filter, kernel_sizes)\n",
    "    outp_short = create_output_short(inp, num_filter)\n",
    "\n",
    "    outp = Add()([outp_long, outp_short])\n",
    "\n",
    "    if len(outp.shape) == 4:     \n",
    "        outp = squeeze(outp, axis=1)\n",
    "\n",
    "    outp = AveragePooling1D(pool_size=pool_size, strides=pool_stride_size)(outp)\n",
    "    \n",
    "    return outp\n",
    "\n",
    "# Spectral Block\n",
    "def spec_temp_block(inp, batch_size):\n",
    "\n",
    "    outp = tf.signal.stft(inp, frame_length=128, frame_step=64)\n",
    "    outp = tf.abs(outp)\n",
    "    outp = LayerNormalization()(outp)\n",
    "    outp = Reshape((8*batch_size,65))(outp)\n",
    "    outp = GRU(64)(outp)\n",
    "    outp = Flatten()(outp)\n",
    "    outp = Dense(32, activation=\"relu\", kernel_regularizer=l2(0.001))(outp)\n",
    "    outp = BatchNormalization()(outp)\n",
    "    \n",
    "    return outp\n",
    "   \n",
    "# Create blocks of the network \n",
    "def net_blocks(batch_size):\n",
    "    inp_time = Input(shape=(batch_size, 624), name=\"input_time0\")\n",
    "    inp_spec = Input(shape=(batch_size, 624), name=\"input_spec0\")\n",
    "\n",
    "    \n",
    "    outp_time = resnet_block(inp_time, batch_size=batch_size, num_filter=64)\n",
    "    outp_spec = spec_temp_block(inp_spec, batch_size=batch_size)\n",
    "\n",
    "    for i in range(0,4):\n",
    "        outp_time = resnet_block(outp_time, batch_size=batch_size, num_filter=128)\n",
    "\n",
    "    model_time = keras.Model(inp_time, outp_time)\n",
    "    model_spec = keras.Model(inp_spec, outp_spec)\n",
    "        \n",
    "    return model_time, model_spec, inp_time, inp_spec, outp_time, outp_spec\n",
    "\n",
    "# Create Batches\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7e5de0",
   "metadata": {},
   "source": [
    "### Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e056dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datagenerator\n",
      "Creating Model\n",
      "Counting Subjects\n",
      "Counting Subjects\n",
      "Epoch 1/5\n",
      "423/423 [==============================] - 180s 410ms/step - loss: 7344.9292 - mae: 78.5229 - val_loss: 18587.7773 - val_mae: 97.7537\n",
      "Epoch 2/5\n",
      "423/423 [==============================] - 150s 354ms/step - loss: 2080.6411 - mae: 35.7300 - val_loss: 1176759.2500 - val_mae: 907.4972\n",
      "Epoch 3/5\n",
      "423/423 [==============================] - 152s 360ms/step - loss: 1538.9128 - mae: 34.1828 - val_loss: 54911.7070 - val_mae: 183.7365\n",
      "Epoch 4/5\n",
      "423/423 [==============================] - 149s 353ms/step - loss: 910.4427 - mae: 23.1567 - val_loss: 1398532.7500 - val_mae: 926.6061\n",
      "Epoch 5/5\n",
      "423/423 [==============================] - 149s 352ms/step - loss: 1519.7834 - mae: 34.3120 - val_loss: 13251.0645 - val_mae: 95.8319\n",
      "Counting Subjects\n",
      "Loading Datagenerator\n",
      "Creating Model\n",
      "Counting Subjects\n",
      "Counting Subjects\n",
      "Epoch 1/5\n",
      "778/778 [==============================] - 280s 352ms/step - loss: 3598.8455 - mae: 55.2480 - val_loss: 41765.2461 - val_mae: 150.7929\n",
      "Epoch 2/5\n",
      "778/778 [==============================] - 281s 361ms/step - loss: 3911.3923 - mae: 51.4781 - val_loss: 2892.6882 - val_mae: 47.6163\n",
      "Epoch 3/5\n",
      "778/778 [==============================] - 280s 361ms/step - loss: 2383.2493 - mae: 42.4976 - val_loss: 17064.4062 - val_mae: 108.4151\n",
      "Epoch 4/5\n",
      "778/778 [==============================] - 279s 359ms/step - loss: 3857.3997 - mae: 51.4787 - val_loss: 2354.1787 - val_mae: 44.7758\n",
      "Counting Subjects\n",
      "Loading Datagenerator\n",
      "Creating Model\n",
      "Counting Subjects\n",
      "Counting Subjects\n",
      "Epoch 1/5\n",
      "850/850 [==============================] - 315s 363ms/step - loss: 2368.1633 - mae: 38.6315 - val_loss: 492068.4062 - val_mae: 646.7318\n",
      "Epoch 2/5\n",
      "850/850 [==============================] - 307s 361ms/step - loss: 955.5421 - mae: 22.7330 - val_loss: 843.0511 - val_mae: 22.6919\n",
      "Epoch 3/5\n",
      "850/850 [==============================] - 306s 360ms/step - loss: 624.3856 - mae: 18.9548 - val_loss: 208266.2500 - val_mae: 409.8828\n",
      "Epoch 4/5\n",
      "850/850 [==============================] - 304s 358ms/step - loss: 881.1393 - mae: 21.5021 - val_loss: 2363.3547 - val_mae: 44.8060\n",
      "Counting Subjects\n"
     ]
    }
   ],
   "source": [
    "# Initialize kfold\n",
    "n_splits = 3\n",
    "kfold = KFold(n_splits=n_splits)\n",
    "kfold.get_n_splits(files)\n",
    "\n",
    "# Initialize Hyperparameter\n",
    "kernel_init = \"he_uniform\"\n",
    "batch_size = 256\n",
    "l2_lambda = 0.001   \n",
    "\n",
    "\n",
    "all_mae_sbp, all_mae_dbp = [], []\n",
    "for train_index, test_index in kfold.split(files): \n",
    "    \n",
    "    # Separate training, validation and test ids\n",
    "    train_index, val_index = train_test_split(train_index, test_size=0.2)\n",
    "    train_id = [files[x] for x in train_index]\n",
    "    val_id = [files[x] for x in val_index]\n",
    "    test_id = [files[x] for x in test_index]\n",
    "    \n",
    "    # Initialize Datagenerator\n",
    "    print(\"Loading Datagenerator\")\n",
    "    generator_train = DataGenerator(path_main, train_id, batch_size=batch_size)\n",
    "    generator_val = DataGenerator(path_main, val_id, batch_size=batch_size)\n",
    "    generator_test = DataGenerator(path_main, test_id, batch_size=batch_size)\n",
    "\n",
    "    # Build ResNet blocks\n",
    "    print(\"Creating Model\")\n",
    "    model_time, model_spec, input_time, input_spec, outp_time, outp_spec = net_blocks(batch_size)\n",
    "    \n",
    "    # Concatenate blocks and build rest of the model\n",
    "    outp_time = Reshape((1, outp_time.shape[1]*outp_time.shape[2]))(outp_time)\n",
    "    outp_time = squeeze(outp_time, axis=1)\n",
    "    merged = concatenate([outp_time, outp_spec])\n",
    "    merged_outp = Dense(32, activation=\"relu\", kernel_regularizer=l2(l2_lambda), kernel_initializer=kernel_init)(merged)\n",
    "    merged_outp = Dropout(0.2)(merged_outp)\n",
    "    merged_outp = Dense(32, activation=\"relu\", kernel_regularizer=l2(l2_lambda), kernel_initializer=kernel_init)(merged_outp)\n",
    "    merged_outp = Dropout(0.2)(merged_outp)\n",
    "    merged_outp = Dense(2, activation='relu')(merged_outp)\n",
    "    \n",
    "    final_model = keras.Model(inputs=[input_time,\n",
    "                            input_spec],\n",
    "                            outputs=merged_outp,\n",
    "                            name='Final_Model')\n",
    "    \n",
    "    # Initialize training\n",
    "    optimizer = optimizers.RMSprop(learning_rate=0.0001)\n",
    "    es = EarlyStopping(monitor=\"mae\", patience=1)\n",
    "    final_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    final_model.fit(generator_train, \n",
    "                    validation_data=generator_val,\n",
    "                    epochs=5,\n",
    "                    verbose=1, \n",
    "                    callbacks=[es])\n",
    "    \n",
    "    all_pred = []\n",
    "    all_true = []\n",
    "    \n",
    "    # Prediction\n",
    "    for batch_index in range(generator_test.__len__()):\n",
    "        #print(batch_index)\n",
    "        batch_data, batch_true_labels = generator_test.__getitem__(batch_index)\n",
    "\n",
    "        batch_pred = final_model.predict(batch_data, verbose=0)\n",
    "        all_pred.append(batch_pred)\n",
    "        sbp_mean = np.mean(batch_true_labels[:,0])\n",
    "        dbp_mean = np.mean(batch_true_labels[:,1])\n",
    "        all_true.append(np.array([sbp_mean, dbp_mean]))\n",
    "\n",
    "    all_pred = np.concatenate(all_pred, axis=0)\n",
    "    all_true = np.array(all_true)\n",
    "\n",
    "    mae_sbp = mean_absolute_error(all_pred[:,0], all_true[:,0])\n",
    "    mae_dbp = mean_absolute_error(all_pred[:,1], all_true[:,1])\n",
    "\n",
    "    all_mae_sbp.append(mae_sbp)\n",
    "    all_mae_dbp.append(mae_dbp)\n",
    "\n",
    "mean_mae_sbp = np.mean(all_mae_sbp)\n",
    "mean_mae_dbp = np.mean(all_mae_dbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dbafc7",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8f022c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE of SBP:  55.74029124720925\n",
      "Mean MAE of DBP:  49.85096200643385\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean MAE of SBP: \", mean_mae_sbp)\n",
    "print(\"Mean MAE of DBP: \", mean_mae_dbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0255a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
